{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from lassonet import LassoNetClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./spambase.data',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.28</td>\n",
       "      <td>3.47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.16</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3     4     5     6     7     8     9     10    11  \\\n",
       "0  0.00  0.64  0.64  0.0  0.32  0.00  0.00  0.00  0.00  0.00  0.00  0.64   \n",
       "1  0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  0.21  0.79   \n",
       "2  0.06  0.00  0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  0.38  0.45   \n",
       "3  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  0.31  0.31   \n",
       "4  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  0.31  0.31   \n",
       "\n",
       "     12    13    14    15    16    17    18    19    20   21    22    23   24  \\\n",
       "0  0.00  0.00  0.00  0.32  0.00  1.29  1.93  0.00  0.96  0.0  0.00  0.00  0.0   \n",
       "1  0.65  0.21  0.14  0.14  0.07  0.28  3.47  0.00  1.59  0.0  0.43  0.43  0.0   \n",
       "2  0.12  0.00  1.75  0.06  0.06  1.03  1.36  0.32  0.51  0.0  1.16  0.06  0.0   \n",
       "3  0.31  0.00  0.00  0.31  0.00  0.00  3.18  0.00  0.31  0.0  0.00  0.00  0.0   \n",
       "4  0.31  0.00  0.00  0.31  0.00  0.00  3.18  0.00  0.31  0.0  0.00  0.00  0.0   \n",
       "\n",
       "    25   26   27   28   29   30   31   32   33   34   35    36   37   38  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.00  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.07  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.00  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.00  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.00  0.0  0.0   \n",
       "\n",
       "     39   40   41    42   43    44    45   46   47    48     49   50     51  \\\n",
       "0  0.00  0.0  0.0  0.00  0.0  0.00  0.00  0.0  0.0  0.00  0.000  0.0  0.778   \n",
       "1  0.00  0.0  0.0  0.00  0.0  0.00  0.00  0.0  0.0  0.00  0.132  0.0  0.372   \n",
       "2  0.06  0.0  0.0  0.12  0.0  0.06  0.06  0.0  0.0  0.01  0.143  0.0  0.276   \n",
       "3  0.00  0.0  0.0  0.00  0.0  0.00  0.00  0.0  0.0  0.00  0.137  0.0  0.137   \n",
       "4  0.00  0.0  0.0  0.00  0.0  0.00  0.00  0.0  0.0  0.00  0.135  0.0  0.135   \n",
       "\n",
       "      52     53     54   55    56  57  \n",
       "0  0.000  0.000  3.756   61   278   1  \n",
       "1  0.180  0.048  5.114  101  1028   1  \n",
       "2  0.184  0.010  9.821  485  2259   1  \n",
       "3  0.000  0.000  3.537   40   191   1  \n",
       "4  0.000  0.000  3.537   40   191   1  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Misc\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "from tqdm import tqdm_notebook\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/liuyue/opt/anaconda3/envs/lab/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/liuyue/opt/anaconda3/envs/lab/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/liuyue/opt/anaconda3/envs/lab/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/liuyue/opt/anaconda3/envs/lab/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/liuyue/opt/anaconda3/envs/lab/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/liuyue/opt/anaconda3/envs/lab/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/liuyue/opt/anaconda3/envs/lab/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/liuyue/opt/anaconda3/envs/lab/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/liuyue/opt/anaconda3/envs/lab/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/liuyue/opt/anaconda3/envs/lab/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/liuyue/opt/anaconda3/envs/lab/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/liuyue/opt/anaconda3/envs/lab/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "# Keras \n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "from Adverse import lowProFool, deepfool\n",
    "from Metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQMAAACQCAYAAAAMVA6SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAWJQAAFiUBSVIk8AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAACpklEQVR4nO3bsYpVVxSA4f84Wtgq2KQxhWARRoivkGdJm86XS5MXmIBTCTZOMU0KISpMEeJOkdWOMIe5cxW/r7nFYW0WXPjZnMvd1loB3Dv2AsDXQQyASgyAIQZAJQbAEAOgEgNgiAFQiQEwxACoxAAYYgBUdX/v4LZtZ9c8+qn6VL3bezaw29Pqw1rrx5sO7o7BF5z04OGjnjx7dICzuQOnlxfHXoGd3vaxqz7vmt1u+y/M27ad9cPpz/32+62ey93569Wvx16BnX7pj877+8+11subznpnAFRiAAwxACoxAIYYAJUYAEMMgEoMgCEGQCUGwBADoBIDYIgBUIkBMMQAqMQAGGIAVGIADDEAKjEAhhgAlRgAQwyASgyAIQZAJQbAEAOgEgNgiAFQiQEwxACoxAAYYgBUYgAMMQAqMQCGGACVGABDDIBKDIAhBkAlBsAQA6ASA2CIAVCJATDEAKjEABhiAFRiAAwxACoxAIYYAJUYAEMMgEoMgCEGQCUGwBADoBIDYIgBUIkBMMQAqMQAGGIAVGIADDEAKjEAhhgAlRgAQwyASgyAIQZAJQbAEAOgEgNgiAFQiQEwxACoxAAYYgBUYgAMMQAqMQCGGACVGABDDIBKDIAhBkAlBsAQA6ASA2CIAVCJATDEAKjEABhiAFRiAAwxACoxAIYYAJUYAEMMgEoMgCEGQCUGwNjWWvsGt+3smkcvevDwpCfP9m/FUZ1eXhx7BXZ628eu+vx+rfX4prP3D7DPvf65+rfL89cHOJvDe37+/+eb467BTk+rD3sGd98Mrj1wbgxrrZe3ejB3wvf3/fLOAKjEABhiAFRiAAwxAKoD/JoAfJvcDIBKDIAhBkAlBsAQA6ASA2CIAVCJATDEAKjEABhiAFRiAAwxAKr6D34TQ5d/WrXDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 144x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 72,
       "width": 129
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Retina display\n",
    "%config InlineBackend.figure_format ='retina'\n",
    "pd.set_option('display.max_columns', 500)\n",
    "tqdm.pandas()\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "ccolors = [\"#008ae9\", \"#ea004f\"]\n",
    "sns.set_palette(ccolors)\n",
    "sns.palplot(sns.color_palette())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GermanNet(nn.Module):\n",
    "        def __init__(self, D_in, H, D_out):\n",
    "            super(GermanNet, self).__init__()\n",
    "            self.linear1 = torch.nn.Linear(D_in, H)\n",
    "            self.linear2 = torch.nn.Linear(H, H)\n",
    "            self.linear3 = torch.nn.Linear(H, D_out)\n",
    "            self.relu = torch.nn.ReLU()\n",
    "            self.softmax = torch.nn.Softmax(dim=0)\n",
    "\n",
    "        def forward(self, x):\n",
    "            h1 = self.relu(self.linear1(x))\n",
    "            h2 = self.relu(self.linear2(h1))\n",
    "            h3 = self.relu(self.linear2(h2))\n",
    "            h4 = self.relu(self.linear2(h3))\n",
    "            h5 = self.relu(self.linear2(h4))\n",
    "            h6 = self.relu(self.linear2(h5))\n",
    "            a3 = self.linear3(h6)\n",
    "            y = self.softmax(a3)\n",
    "            return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, X, y, N, n_classes):\n",
    "        model.train()\n",
    "\n",
    "        current_loss = 0\n",
    "        current_correct = 0\n",
    "\n",
    "\n",
    "        # Training in batches\n",
    "        for ind in range(0, X.size(0), N):\n",
    "            indices = range(ind, min(ind + N, X.size(0)) - 1) \n",
    "            inputs, labels = X[indices], y[indices]\n",
    "            inputs = Variable(inputs, requires_grad=True)\n",
    "\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(inputs)\n",
    "            print(output)\n",
    "            \n",
    "            if output[0] == output[1]:\n",
    "                indices = random.randint(0,1)\n",
    "            else:\n",
    "                _, indices = torch.max(output, 1) # argmax of output [[0.61, 0.12]] -> [0]\n",
    "            # [[0, 1, 1, 0, 1, 0, 0]] -> [[1, 0], [0, 1], [0, 1], [1, 0], [0, 1], [1, 0], [1, 0]]\n",
    "            preds = torch.tensor(keras.utils.to_categorical(indices, num_classes=n_classes))\n",
    "\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            current_loss += loss.item()\n",
    "            current_correct += (preds.int() == labels.int()).sum() /n_classes\n",
    "\n",
    "\n",
    "        current_loss = current_loss / X.size(0)\n",
    "        current_correct = current_correct.double() / X.size(0)    \n",
    "\n",
    "        return preds, current_loss, current_correct.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),\n",
       "indices=tensor([1, 1, 1,  ..., 0, 0, 0]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(y_train,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_adv(config, method):\n",
    "    df_test = config['TestData']\n",
    "    extra_cols = ['orig_pred', 'adv_pred', 'iters']    \n",
    "    model = config['Model']\n",
    "    weights = config['Weights']\n",
    "    bounds = config['Bounds']\n",
    "    maxiters = config['MaxIters']\n",
    "    alpha = config['Alpha']\n",
    "    lambda_ = config['Lambda']\n",
    "    \n",
    "    results = np.zeros((len(df_test), len(feature_names) + len(extra_cols)))    \n",
    "            \n",
    "    i = -1\n",
    "    \n",
    "    for _, row in tqdm_notebook(df_test.iterrows(), total=df_test.shape[0], desc=\"{}\".format(method)):\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "        x_tensor = torch.FloatTensor(row[config['FeatureNames']])   \n",
    "        \n",
    "        if method == 'LowProFool':\n",
    "            orig_pred, adv_pred, x_adv, loop_i = lowProFool(x_tensor, model, weights, bounds,\n",
    "                                                             maxiters, alpha, lambda_)\n",
    "        elif method == 'Deepfool':\n",
    "            orig_pred, adv_pred, x_adv, loop_i = deepfool(x_tensor, model, maxiters, alpha,\n",
    "                                                          bounds, weights=[])\n",
    "        else:\n",
    "            raise Exception(\"Invalid method\", method)\n",
    "        results[i] = np.concatenate((x_adv, [orig_pred, adv_pred, loop_i]), axis=0)\n",
    "        \n",
    "    return pd.DataFrame(results, index=df_test.index, columns = feature_names + extra_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df, target, feature_names, bounds):\n",
    "    df_return = df.copy()\n",
    "    \n",
    "    # Makes sure target does not need scaling\n",
    "    targets = np.unique(df[target].values)\n",
    "    assert(len(targets == 2) and 0. in targets and 1. in targets)\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    X = df_return[feature_names]\n",
    "    scaler.fit(X)    \n",
    "    df_return[feature_names] = scaler.transform(X)\n",
    "    \n",
    "    lower_bounds = scaler.transform([bounds[0]])\n",
    "    upper_bounds = scaler.transform([bounds[1]])\n",
    "\n",
    "    return scaler, df_return, (lower_bounds[0], upper_bounds[0])\n",
    "\n",
    "def get_weights(df, target, show_heatmap=False):\n",
    "    def heatmap(cor):\n",
    "        plt.figure(figsize=(8,6))\n",
    "        sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\n",
    "        plt.show()\n",
    "\n",
    "    cor = df.corr()\n",
    "    cor_target = abs(cor[target])\n",
    "\n",
    "    weights = cor_target[:-1] #removing target WARNING ASSUMES TARGET IS LAST\n",
    "    weights = weights / np.linalg.norm(weights)\n",
    "\n",
    "    if show_heatmap:\n",
    "        heatmap(cor)\n",
    "            \n",
    "    return weights.values\n",
    "\n",
    "def balance_df(df):\n",
    "    len_df_0, len_df_1 = len(df[df[target] == 0.]), len(df[df[target] == 1.])\n",
    "    df_0 = df[df[target] == 0.].sample(min(len_df_0, len_df_1), random_state=SEED)\n",
    "    df_1 = df[df[target] == 1.].sample(min(len_df_0, len_df_1), random_state=SEED)\n",
    "    df = pd.concat((df_0, df_1))\n",
    "    return df\n",
    "\n",
    "def get_bounds():\n",
    "    low_bounds = df_orig.min().values\n",
    "    up_bounds = df_orig.max().values\n",
    "    \n",
    "    #removing target WARNING ASSUMES TARGET IS LAST\n",
    "    low_bounds = low_bounds[:-1]\n",
    "    up_bounds = up_bounds[:-1]\n",
    "    \n",
    "    return [low_bounds, up_bounds]\n",
    "\n",
    "def split_train_test_valid():\n",
    "    # Train test splits\n",
    "    df_train, df_test = train_test_split(df, test_size=300, shuffle=True, random_state=SEED)\n",
    "    df_test, df_valid = train_test_split(df_test, test_size=50, shuffle=True, random_state=SEED)\n",
    "    \n",
    "    return df_train, df_test, df_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0102, 0.0092],\n",
      "        [0.0082, 0.0124],\n",
      "        [0.0046, 0.0225],\n",
      "        [0.0106, 0.0089],\n",
      "        [0.0106, 0.0089],\n",
      "        [0.0112, 0.0084],\n",
      "        [0.0110, 0.0086],\n",
      "        [0.0112, 0.0084],\n",
      "        [0.0061, 0.0147],\n",
      "        [0.0092, 0.0109],\n",
      "        [0.0113, 0.0084],\n",
      "        [0.0108, 0.0088],\n",
      "        [0.0102, 0.0092],\n",
      "        [0.0113, 0.0084],\n",
      "        [0.0106, 0.0089],\n",
      "        [0.0103, 0.0091],\n",
      "        [0.0109, 0.0086],\n",
      "        [0.0093, 0.0102],\n",
      "        [0.0111, 0.0085],\n",
      "        [0.0104, 0.0089],\n",
      "        [0.0112, 0.0085],\n",
      "        [0.0061, 0.0192],\n",
      "        [0.0112, 0.0084],\n",
      "        [0.0111, 0.0084],\n",
      "        [0.0110, 0.0085],\n",
      "        [0.0061, 0.0192],\n",
      "        [0.0110, 0.0085],\n",
      "        [0.0112, 0.0084],\n",
      "        [0.0112, 0.0084],\n",
      "        [0.0107, 0.0086],\n",
      "        [0.0112, 0.0084],\n",
      "        [0.0111, 0.0084],\n",
      "        [0.0111, 0.0085],\n",
      "        [0.0113, 0.0085],\n",
      "        [0.0104, 0.0091],\n",
      "        [0.0112, 0.0085],\n",
      "        [0.0112, 0.0084],\n",
      "        [0.0102, 0.0091],\n",
      "        [0.0105, 0.0089],\n",
      "        [0.0098, 0.0093],\n",
      "        [0.0105, 0.0090],\n",
      "        [0.0112, 0.0084],\n",
      "        [0.0112, 0.0084],\n",
      "        [0.0111, 0.0084],\n",
      "        [0.0102, 0.0094],\n",
      "        [0.0086, 0.0114],\n",
      "        [0.0101, 0.0097],\n",
      "        [0.0110, 0.0085],\n",
      "        [0.0047, 0.0266],\n",
      "        [0.0088, 0.0115],\n",
      "        [0.0112, 0.0084],\n",
      "        [0.0106, 0.0088],\n",
      "        [0.0091, 0.0109],\n",
      "        [0.0111, 0.0085],\n",
      "        [0.0107, 0.0088],\n",
      "        [0.0109, 0.0086],\n",
      "        [0.0106, 0.0087],\n",
      "        [0.0111, 0.0084],\n",
      "        [0.0104, 0.0089],\n",
      "        [0.0098, 0.0093],\n",
      "        [0.0102, 0.0091],\n",
      "        [0.0111, 0.0084],\n",
      "        [0.0111, 0.0085],\n",
      "        [0.0110, 0.0086],\n",
      "        [0.0106, 0.0088],\n",
      "        [0.0108, 0.0086],\n",
      "        [0.0105, 0.0089],\n",
      "        [0.0113, 0.0085],\n",
      "        [0.0101, 0.0094],\n",
      "        [0.0107, 0.0087],\n",
      "        [0.0095, 0.0100],\n",
      "        [0.0105, 0.0089],\n",
      "        [0.0099, 0.0093],\n",
      "        [0.0110, 0.0086],\n",
      "        [0.0102, 0.0091],\n",
      "        [0.0095, 0.0096],\n",
      "        [0.0110, 0.0086],\n",
      "        [0.0084, 0.0123],\n",
      "        [0.0108, 0.0088],\n",
      "        [0.0113, 0.0084],\n",
      "        [0.0109, 0.0086],\n",
      "        [0.0086, 0.0103],\n",
      "        [0.0111, 0.0084],\n",
      "        [0.0112, 0.0084],\n",
      "        [0.0108, 0.0086],\n",
      "        [0.0103, 0.0090],\n",
      "        [0.0108, 0.0087],\n",
      "        [0.0109, 0.0086],\n",
      "        [0.0084, 0.0118],\n",
      "        [0.0113, 0.0084],\n",
      "        [0.0103, 0.0089],\n",
      "        [0.0047, 0.0266],\n",
      "        [0.0036, 0.0261],\n",
      "        [0.0036, 0.0261],\n",
      "        [0.0110, 0.0086],\n",
      "        [0.0110, 0.0085],\n",
      "        [0.0101, 0.0094],\n",
      "        [0.0103, 0.0090],\n",
      "        [0.0107, 0.0088]], grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "bool value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-61272f54ea43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"> epoch {:.0f}\\tLoss {:.5f}\\tAcc {:.5f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-cd0f7e9711bc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, criterion, optimizer, X, y, N, n_classes)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                 \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: bool value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "feature_names = df.columns.values[:-1]\n",
    "target = 57\n",
    "\n",
    "n_classes = len(np.unique(df[target]))\n",
    "X_train = torch.FloatTensor(df[feature_names].values)\n",
    "y_train = keras.utils.to_categorical(df[target], n_classes)\n",
    "y_train = torch.FloatTensor(y_train)\n",
    "\n",
    "\n",
    "D_in = X_train.size(1)\n",
    "D_out = y_train.size(1)\n",
    "\n",
    "epochs = 400\n",
    "batch_size = 100\n",
    "H = 100\n",
    "net = GermanNet(D_in, H, D_out)\n",
    "\n",
    "\n",
    "lr = 1e-4    \n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    preds, epoch_loss, epoch_acc = train(net, criterion, optimizer, X_train, y_train, batch_size, n_classes)     \n",
    "    if (epoch % 50 == 0):\n",
    "        print(\"> epoch {:.0f}\\tLoss {:.5f}\\tAcc {:.5f}\".format(epoch, epoch_loss, epoch_acc))\n",
    "\n",
    "net.eval()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
