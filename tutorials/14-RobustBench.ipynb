{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing attacks against RobustBench models\n",
    "\n",
    "In this tutorial, we will show how to correctly import [RobustBench](\n",
    "https://github.com/RobustBench/robustbench) models inside SecML,\n",
    "and how to craft adversarial evasion attacks against them using SecML.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](\n",
    "https://colab.research.google.com/github/pralab/secml/blob/HEAD/tutorials/14-RobustBench.ipynb)\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**Warning**\n",
    "\n",
    "Requires installation of the `pytorch` extra dependency.\n",
    "See [extra components](../index.rst#extra-components) for more information.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr --no-display\n",
    "# NBVAL_IGNORE_OUTPUT\n",
    "\n",
    "try:\n",
    "  import secml\n",
    "  import torch\n",
    "except ImportError:\n",
    "  %pip install git+https://gitlab.com/secml/secml#egg=secml[pytorch]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We start by installing the models offered by RobustBench, a repository of\n",
    "pre-trained adversarially robust models, written in PyTorch.\n",
    "All the models are trained on CIFAR-10.\n",
    "To install the library, just open a terminal and execute the following command:\n",
    "\n",
    "```bash\n",
    "pip install git+https://github.com/RobustBench/robustbench.git@v0.1```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr --no-display\n",
    "# NBVAL_IGNORE_OUTPUT\n",
    "\n",
    "try:\n",
    "  import robustbench\n",
    "except ImportError:\n",
    "  %pip install git+https://github.com/RobustBench/robustbench.git@v0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "After the installation, we can import the model we like among the one\n",
    "offered by the library ([click here](\n",
    "https://github.com/RobustBench/robustbench/tree/master/model_info) for the complete list):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'robustbench'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-09212ebc7d86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# NBVAL_IGNORE_OUTPUT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrobustbench\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msecml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msecml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'robustbench'"
     ]
    }
   ],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "\n",
    "from robustbench.utils import load_model\n",
    "from secml.utils import fm\n",
    "from secml import settings\n",
    "\n",
    "output_dir = fm.join(settings.SECML_MODELS_DIR, 'robustbench')\n",
    "model = load_model(model_name='Carmon2019Unlabeled', norm='Linf', model_dir=output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command will create a `models` directory inside the `secml-data` folder in your home directory, where it will download the desired model, specified by the `model_name` parameter.\n",
    "Since it is a PyTorch model, we can just load one sample from CIFAR-10 to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "\n",
    "from secml.data.loader.c_dataloader_cifar import CDataLoaderCIFAR10\n",
    "train_ds, test_ds = CDataLoaderCIFAR10().load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from secml.ml.features.normalization import CNormalizerMinMax\n",
    "\n",
    "dataset_labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "normalizer = CNormalizerMinMax().fit(train_ds.X)\n",
    "pt = test_ds[0, :]\n",
    "x0, y0 = pt.X, pt.Y\n",
    "\n",
    "x0 = normalizer.transform(x0)\n",
    "input_shape = (3, 32, 32)\n",
    "\n",
    "x0_t = x0.tondarray().reshape(1, 3, 32, 32)\n",
    "\n",
    "y_pred = model(torch.Tensor(x0_t))\n",
    "\n",
    "print(\"Predicted classes: {0}\".format(dataset_labels[y_pred.argmax(axis=1).item()]))\n",
    "print(\"Real classes: {0}\".format(dataset_labels[y0.item()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load RobustBench models inside SecML\n",
    "\n",
    "We can now import the pre-trained robust model inside SecML. Since these models are all coded in PyTorch, we just need to use the PyTorch wrapper of SecML.\n",
    "\n",
    "In order to do this, we need to express the `input_shape` of the data, and feed the classifier with the flatten version of the array (under the hood, the framework will reconstruct the original shape):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secml.ml.classifiers import CClassifierPyTorch\n",
    "\n",
    "secml_model = CClassifierPyTorch(model, input_shape=(3,32,32), pretrained=True)\n",
    "y_pred = secml_model.predict(x0)\n",
    "print(\"Predicted class: {0}\".format(dataset_labels[y_pred.item()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing evasion attacks\n",
    "\n",
    "Now that we have imported the model inside SecML, we can compute attacks against it.\n",
    "We will use the iterative Projected Gradient Descent (PGD) attack, with `l2` perturbation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secml.adv.attacks.evasion import CAttackEvasionPGD\n",
    "\n",
    "noise_type = 'l2'   # Type of perturbation 'l1' or 'l2'\n",
    "dmax = 0.5          # Maximum perturbation\n",
    "lb, ub = 0, 1       # Bounds of the attack space. Can be set to `None` for unbounded\n",
    "y_target = None     # None if `error-generic` or a class label for `error-specific`\n",
    "\n",
    "# Should be chosen depending on the optimization problem\n",
    "solver_params = {\n",
    "    'eta': 0.4,\n",
    "    'max_iter': 100, \n",
    "    'eps': 1e-3\n",
    "}\n",
    "\n",
    "pgd_ls_attack = CAttackEvasionPGD(\n",
    "    classifier=secml_model,\n",
    "    double_init_ds=test_ds[0, :],\n",
    "    distance=noise_type,\n",
    "    dmax=dmax,\n",
    "    lb=lb, ub=ub,\n",
    "    solver_params=solver_params,\n",
    "    y_target=y_target\n",
    ")\n",
    "\n",
    "y_pred_pgd, _, adv_ds_pgd, _ = pgd_ls_attack.run(x0, y0)\n",
    "print(\"Real class: {0}\".format(dataset_labels[y0.item()]))\n",
    "print(\"Predicted class after the attack: {0}\".format(dataset_labels[y_pred_pgd.item()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from secml.figure import CFigure\n",
    "%matplotlib inline\n",
    "\n",
    "img_normal = x0.tondarray().reshape((3,32,32)).transpose(2,1,0)\n",
    "img_adv = adv_ds_pgd.X[0,:].tondarray().reshape((3,32,32)).transpose(2,1,0)\n",
    "\n",
    "diff_img = img_normal - img_adv\n",
    "diff_img -= diff_img.min()\n",
    "diff_img /= diff_img.max()\n",
    "\n",
    "fig = CFigure()\n",
    "fig.subplot(1,3,1)\n",
    "fig.sp.imshow(img_normal)\n",
    "fig.sp.title('{0}'.format(dataset_labels[y0.item()]))\n",
    "fig.sp.xticks([])\n",
    "fig.sp.yticks([])\n",
    "\n",
    "fig.subplot(1,3,2)\n",
    "fig.sp.imshow(img_adv)\n",
    "fig.sp.title('{0}'.format(dataset_labels[y_pred_pgd.item()]))\n",
    "fig.sp.xticks([])\n",
    "fig.sp.yticks([])\n",
    "\n",
    "\n",
    "fig.subplot(1,3,3)\n",
    "fig.sp.imshow(diff_img)\n",
    "fig.sp.title('Amplified perturbation')\n",
    "fig.sp.xticks([])\n",
    "fig.sp.yticks([])\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
